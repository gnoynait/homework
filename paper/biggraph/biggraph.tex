\documentclass {report}
\usepackage{graphicx}

\usepackage{algorithm}
\usepackage{algpseudocode}

\begin{document}
\title{Big Graph Tools}
\author{Tian Yong}
\maketitle
\chapter{Introduction}
\section{Introduction}
There are several choices to implement an algorithm to process a large graph:
\begin{itemize}
  \item Crafting a custom distributed infrastructure. This choice leaves machine learning experts repeatedly design a system and implement it.
  \item Relying on an existing distributed computing platform like MapReduce, which is not suit for graph processing.
  \item Using a single-computer graph algorithm library limiting the scale of problems that can addressed.
  \item Using an parallel graph system, fault tolerance or not.
\end{itemize}
\section{Pregel}
The input to a Pregel computation is a directed graph in
which each vertex is uniquely identified by a string vertex
identifier. Each vertex is associated with a modifiable, user
defined value. The directed edges are associated with their
source vertices, and each edge consists of a modifiable, user
defined value and a target vertex identifier.


Pregel computations consist of a sequence of iterations, called \emph{supersteps}. During a superstep the framework invokes a userdefined function for each vertex, conceptually in parallel.
The function specifies behavior at a single vertex $V$ and a
single superstep $S$. It can read messages sent to $V$ in superstep $S-1$, send messages to other vertices that will be received at superstep $S + 1$, and modify the state of $V$ and
its outgoing edges. Messages are typically sent along outgoing edges, but a message may be sent to any vertex whose
identifier is known.  All communication is from superstep $S$ to superstep $S + 1$. In supersteps, vertex can even change the topology of the graph.

Algorithm termination is based on every vertex voting to
halt. In superstep 0, every vertex is in the active state; all
active vertices participate in the computation of any given
superstep. A vertex deactivates itself by voting to halt. This
means that the vertex has no further work to do unless triggered externally, and the Pregel framework will not execute
that vertex in subsequent supersteps unless it receives a message. If reactivated by a message, a vertex must explicitly deactivate itself again. The algorithm as a whole terminates
when all vertices are simultaneously inactive and there are
no messages in transit. This state transition model is illustrated in figure \ref{SMachine}.


\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=\textwidth]{pregel_vertext_machine.PNG}\\
  \caption{Pregel Vertext State Machine}\label{SMachine}
\end{figure}

Figure \ref{pregel_max} illustrates these concepts using a simple example:
given a strongly connected graph where each vertex contains
a value, it propagates the largest value to every vertex. In
each superstep, any vertex that has learned a larger value
from its messages sends it to all its neighbors. When no
further vertices change in a superstep, the algorithm terminates
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=\textwidth]{pregel_max_example.PNG}\\
  \caption{Maximum Value Example. Dotted lines
are messages. Shaded vertices have voted to halt.}\label{pregel_max}
\end{figure}


\subsection{Topology Mutations}
Some graph algorithms need to change the graph's topology. A clustering algorithm, for example, might replace each
cluster with a single vertex, and a minimum spanning tree
algorithm might remove all but the tree edges. User defined function can not only send messages, but also can
issue requests to add or remove vertices or edges.


Multiple vertices may issue conflicting requests in the same
superstep. To solve this problem, Pregel use two mechanisms to achieve
determinism:
\begin{itemize}
  \item Partial ordering. As with messages, mutations become elective in the superstep after the requests were
  issued. Within that superstep removals are performed first, with edge removal before vertex removal. Then additions follow, with vertex addition before edge addition. This partial ordering yields deterministic results for most conflicts.
  \item Handlers. The remaining conflicts are resolved by user-defined handlers. For these conflicts, system have a default random resolution. Butt users with special needs may specify a better conflict resolution policy by defining an appropriate handler method.
\end{itemize}

\section{GraphLab}
GraphLab is a parallel framework for ML which exploits the sparse structure and common computational patterns of ML algorithms. GraphLab
enables ML experts to easily design and implement efficient scalable parallel algorithms by composing problem
specific computation, data-dependencies, and scheduling. GraphLab is implemented with an efficient shared-memory mechanism for it is both ubiquitous and has
few effective high-level abstractions.

\subsection{Data Model}
The GraphLab data model consists of two parts: a directed \emph{data graph} and a \emph{shared data table}. The data graph is arbitrary data block associated
with vertex or edges in a graph while a shared data table(SDT) is an associative map between keys and arbitrary blocks of data to support globally shared state or data.
\subsection{User Defined Computation}
There are two kinds of computation in GraphLab: update and sync. Update functions are permitted to access and modify overlapping contexts in the graph and do local computations. Sync is used to global aggregation and it runs concurrently with update functions.


A GraphLab update function is a stateless user-defined
function which operates on the data associated with small
neighborhoods in the graph and represents the core element
of computation. Given arbitrary vertex $v$, $S_v$ represents the
neighborhood of $v$ which consists of $v$, its adjacent edges
(both inbound and outbound) and its neighboring vertices. And $D_{S_v}$ stands for the data corresponding to the neighborhood $S_v$
. In addition to $D_{S_v}$, update functions also have read-only access, to the shared
data table $T$. An update function $f$ to the vertex $v$ is:
\begin{equation}
  D_{S_v} \leftarrow f(D_{S_v}, T).
\end{equation}

A GraphLab program may consist of
multiple update functions and it is up to the scheduling
model to determine which update functions
are applied to which vertices and in which parallel order.


The sync mechanism aggregates data across all vertices in
the graph and its result is associated with a particular entry int the SDT. To invoke a sync mechanism, user
should provide a key $k$, a \textbf{fold function}(Eq. (\ref{fold_function})), an \textbf{appply function}(Eq. (\ref{apply_function})) as well as an initial value $r^{(0)}_k$ to the SDT.
\begin{equation}\label{fold_function}
r^{i+1}_k \leftarrow Fold_k (D_v, r^{i}_k)
\end{equation}
\begin{equation}\label{apply_function}
  T[k] \leftarrow Apply_k(r_k^{(|V|)})
\end{equation}

When the sync mechanism is invoked, the algorithm in
Alg.\ref{sync_algo} uses the $Fold_k $
function to sequentially aggregate
data across all vertices. The sync mechanism can be set to run periodically in the
background while the GraphLab engine is actively applying update functions or on demand triggered by update
functions or user code. If the sync mechanism is executed
in the background, the resulting aggregated value may not
be globally consistent. Nonetheless, many ML applications
are robust to approximate global statistics.


\begin{algorithm}
\caption{Sync algorithm on k}
\label{sync_algo}
\begin{algorithmic}[1]
\Procedure {SYNC}{$k$, $r_k^{(0)}$}
    \State $t \leftarrow r_k^{(0)}$
    \ForAll {$v \in V$}
        \State $t \leftarrow Fold_k(D_v, t)$
    \EndFor
    \State $T[k] \leftarrow Apply_k(t)$

\EndProcedure


\end{algorithmic}
\end{algorithm}

\subsection{Data Consistency}
Since scopes may overlap, the simultaneous execution of
two update functions can lead to race-conditions resulting
in data inconsistency and even corruption. GraphLab provides
 a choice of three data consistency models which enable the user
  to balance performance and data consistency. The 3 models is illustrated in Figure \ref{graphlab_scope}
   by drawing their exclusion sets as a ring where no two update functions
    may be executed simultaneously if their exclusions sets overlap
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=\textwidth]{graphlab_scope}\\
  \caption{(a) The scope, $S_v$ of vertex $v$. (b). Three data consistency
   models.}\label{graphlab_scope}
\end{figure}



\subsection{Scheduling}
The GraphLab update schedule describes the order in
which update functions are applied to vertices and is represented by a parallel data-structure called the scheduler.
The scheduler abstractly represents a dynamic list of tasks
(vertex-function pairs) which are to be executed by the
GraphLab engine. GraphLab framework provides a collection of base schedules to achieve different goals.

GraphLab also provide 2 termination assessment methods. The first method relies on
the scheduler which signals termination when there are no
remaining tasks. The second termination
method relies on user provided termination functions which
examine the SDT and signal when the algorithm has converged.


\section{PowerGraph}
\section{Graphchi}
\end{document}
